{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3c8c632",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa.display\n",
    "import keras\n",
    "import IPython.display as ipd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "837d94ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>fold</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>do001.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>cryandsob</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>do002.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>cryandsob</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>do003.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>cryandsob</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>do004.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>cryandsob</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>do005.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>cryandsob</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   file_name  fold      class\n",
       "0  do001.wav     1  cryandsob\n",
       "1  do002.wav     1  cryandsob\n",
       "2  do003.wav     1  cryandsob\n",
       "3  do004.wav     1  cryandsob\n",
       "4  do005.wav     1  cryandsob"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_dataset_path=(r'C:\\Users\\hpmsi\\Downloads\\output-20220411T164542Z-001\\combined')\n",
    "metadata=pd.read_csv(r\"C:\\Users\\hpmsi\\Downloads\\output-20220411T164542Z-001\\comb_meta\\com.csv\")\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ddc423e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_extractor(file):\n",
    "    audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n",
    "    mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "    mfccs_scaled_features = np.mean(mfccs_features.T,axis=0)\n",
    "    \n",
    "    return mfccs_scaled_features\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "920ebed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1421it [01:10, 20.04it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "### Now we iterate through every audio file and extract features \n",
    "### using Mel-Frequency Cepstral Coefficients\n",
    "extracted_features=[]\n",
    "for index_num,row in tqdm(metadata.iterrows()):\n",
    "    file_name = os.path.join(os.path.abspath(audio_dataset_path),'fold'+str(row[\"fold\"])+'/',str(row[\"file_name\"]))\n",
    "    final_class_labels=row[\"class\"]\n",
    "    data=features_extractor(file_name)\n",
    "    extracted_features.append([data,final_class_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "665f2578",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-327.12015, 129.83017, -70.920944, -41.29247,...</td>\n",
       "      <td>cryandsob</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-200.72635, 91.268654, -84.3782, 34.001503, -...</td>\n",
       "      <td>cryandsob</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-361.73053, 115.61554, -68.29292, 15.610739, ...</td>\n",
       "      <td>cryandsob</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-349.65146, 137.25008, -59.295837, 28.300783,...</td>\n",
       "      <td>cryandsob</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-433.82852, 111.65828, -27.588154, 6.815115, ...</td>\n",
       "      <td>cryandsob</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             feature      class\n",
       "0  [-327.12015, 129.83017, -70.920944, -41.29247,...  cryandsob\n",
       "1  [-200.72635, 91.268654, -84.3782, 34.001503, -...  cryandsob\n",
       "2  [-361.73053, 115.61554, -68.29292, 15.610739, ...  cryandsob\n",
       "3  [-349.65146, 137.25008, -59.295837, 28.300783,...  cryandsob\n",
       "4  [-433.82852, 111.65828, -27.588154, 6.815115, ...  cryandsob"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### converting extracted_features to Pandas dataframe\n",
    "extracted_features_df=pd.DataFrame(extracted_features,columns=['feature','class'])\n",
    "extracted_features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a489225",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array(extracted_features_df['feature'].tolist())\n",
    "y=np.array(extracted_features_df['class'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e00a48a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['cryandsob', 'cryandsob', 'cryandsob', ..., 'sad', 'sad', 'sad'],\n",
       "      dtype='<U9')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32794d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Label Encoding\n",
    "###y=np.array(pd.get_dummies(y))\n",
    "### Label Encoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder=LabelEncoder()\n",
    "y=to_categorical(labelencoder.fit_transform(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ddff9aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train Test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6b3faa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec95b35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97fd18bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "### No of classes\n",
    "num_labels=y.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c074390c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "###first layer\n",
    "model.add(Dense(100,input_shape=(40,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "###second layer\n",
    "model.add(Dense(200))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "###third layer\n",
    "model.add(Dense(100))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "###final layer\n",
    "model.add(Dense(num_labels))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "08e77281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 100)               4100      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 200)               20200     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 7)                 707       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 7)                 0         \n",
      "=================================================================\n",
      "Total params: 45,107\n",
      "Trainable params: 45,107\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5fb8f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c24b4911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "19/36 [==============>...............] - ETA: 0s - loss: 0.2228 - accuracy: 0.9095\n",
      "Epoch 00001: val_loss improved from inf to 0.48847, saving model to saved_models\\audio_classification.hdf5\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.2457 - accuracy: 0.8970 - val_loss: 0.4885 - val_accuracy: 0.8211\n",
      "Epoch 2/250\n",
      "23/36 [==================>...........] - ETA: 0s - loss: 0.2362 - accuracy: 0.8995\n",
      "Epoch 00002: val_loss improved from 0.48847 to 0.43222, saving model to saved_models\\audio_classification.hdf5\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.2506 - accuracy: 0.8952 - val_loss: 0.4322 - val_accuracy: 0.8386\n",
      "Epoch 3/250\n",
      "26/36 [====================>.........] - ETA: 0s - loss: 0.2728 - accuracy: 0.8870\n",
      "Epoch 00003: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2633 - accuracy: 0.8891 - val_loss: 0.4551 - val_accuracy: 0.8386\n",
      "Epoch 4/250\n",
      "27/36 [=====================>........] - ETA: 0s - loss: 0.2283 - accuracy: 0.8993\n",
      "Epoch 00004: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2328 - accuracy: 0.8970 - val_loss: 0.4486 - val_accuracy: 0.8281\n",
      "Epoch 5/250\n",
      "27/36 [=====================>........] - ETA: 0s - loss: 0.2532 - accuracy: 0.8970\n",
      "Epoch 00005: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2354 - accuracy: 0.9014 - val_loss: 0.4564 - val_accuracy: 0.8421\n",
      "Epoch 6/250\n",
      "23/36 [==================>...........] - ETA: 0s - loss: 0.1979 - accuracy: 0.9062\n",
      "Epoch 00006: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2223 - accuracy: 0.8996 - val_loss: 0.4646 - val_accuracy: 0.8386\n",
      "Epoch 7/250\n",
      "27/36 [=====================>........] - ETA: 0s - loss: 0.2204 - accuracy: 0.9051\n",
      "Epoch 00007: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2192 - accuracy: 0.9058 - val_loss: 0.4953 - val_accuracy: 0.8316\n",
      "Epoch 8/250\n",
      "27/36 [=====================>........] - ETA: 0s - loss: 0.2045 - accuracy: 0.9016\n",
      "Epoch 00008: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2043 - accuracy: 0.9049 - val_loss: 0.4985 - val_accuracy: 0.8281\n",
      "Epoch 9/250\n",
      "26/36 [====================>.........] - ETA: 0s - loss: 0.1974 - accuracy: 0.9062\n",
      "Epoch 00009: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2012 - accuracy: 0.9085 - val_loss: 0.4816 - val_accuracy: 0.8246\n",
      "Epoch 10/250\n",
      "27/36 [=====================>........] - ETA: 0s - loss: 0.2139 - accuracy: 0.9109\n",
      "Epoch 00010: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2292 - accuracy: 0.9085 - val_loss: 0.4797 - val_accuracy: 0.8105\n",
      "Epoch 11/250\n",
      "29/36 [=======================>......] - ETA: 0s - loss: 0.2338 - accuracy: 0.9019\n",
      "Epoch 00011: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2406 - accuracy: 0.9014 - val_loss: 0.4591 - val_accuracy: 0.8316\n",
      "Epoch 12/250\n",
      "25/36 [===================>..........] - ETA: 0s - loss: 0.2187 - accuracy: 0.8975\n",
      "Epoch 00012: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2116 - accuracy: 0.9067 - val_loss: 0.4926 - val_accuracy: 0.8175\n",
      "Epoch 13/250\n",
      "26/36 [====================>.........] - ETA: 0s - loss: 0.1925 - accuracy: 0.9147 ETA: 0s - loss: 0.1885 - accuracy: 0.90\n",
      "Epoch 00013: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1907 - accuracy: 0.9190 - val_loss: 0.4621 - val_accuracy: 0.8246\n",
      "Epoch 14/250\n",
      "25/36 [===================>..........] - ETA: 0s - loss: 0.2196 - accuracy: 0.9075\n",
      "Epoch 00014: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2180 - accuracy: 0.9085 - val_loss: 0.4966 - val_accuracy: 0.8105\n",
      "Epoch 15/250\n",
      "26/36 [====================>.........] - ETA: 0s - loss: 0.2104 - accuracy: 0.91 - ETA: 0s - loss: 0.2200 - accuracy: 0.9123\n",
      "Epoch 00015: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2231 - accuracy: 0.9137 - val_loss: 0.4620 - val_accuracy: 0.8281\n",
      "Epoch 16/250\n",
      "27/36 [=====================>........] - ETA: 0s - loss: 0.2172 - accuracy: 0.9051\n",
      "Epoch 00016: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2201 - accuracy: 0.9032 - val_loss: 0.4828 - val_accuracy: 0.8246\n",
      "Epoch 17/250\n",
      "27/36 [=====================>........] - ETA: 0s - loss: 0.2219 - accuracy: 0.8993\n",
      "Epoch 00017: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2161 - accuracy: 0.9058 - val_loss: 0.5030 - val_accuracy: 0.8281\n",
      "Epoch 18/250\n",
      "27/36 [=====================>........] - ETA: 0s - loss: 0.2297 - accuracy: 0.9028\n",
      "Epoch 00018: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2368 - accuracy: 0.8988 - val_loss: 0.4479 - val_accuracy: 0.8351\n",
      "Epoch 19/250\n",
      "26/36 [====================>.........] - ETA: 0s - loss: 0.2181 - accuracy: 0.9026\n",
      "Epoch 00019: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2058 - accuracy: 0.9076 - val_loss: 0.4999 - val_accuracy: 0.8211\n",
      "Epoch 20/250\n",
      "26/36 [====================>.........] - ETA: 0s - loss: 0.1746 - accuracy: 0.9219\n",
      "Epoch 00020: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1875 - accuracy: 0.9120 - val_loss: 0.5208 - val_accuracy: 0.8456\n",
      "Epoch 21/250\n",
      "25/36 [===================>..........] - ETA: 0s - loss: 0.2167 - accuracy: 0.9062\n",
      "Epoch 00021: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2145 - accuracy: 0.9093 - val_loss: 0.4861 - val_accuracy: 0.8421\n",
      "Epoch 22/250\n",
      "29/36 [=======================>......] - ETA: 0s - loss: 0.2162 - accuracy: 0.9030\n",
      "Epoch 00022: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2140 - accuracy: 0.9023 - val_loss: 0.4832 - val_accuracy: 0.8281\n",
      "Epoch 23/250\n",
      "31/36 [========================>.....] - ETA: 0s - loss: 0.2194 - accuracy: 0.9133\n",
      "Epoch 00023: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2290 - accuracy: 0.9040 - val_loss: 0.4975 - val_accuracy: 0.8351\n",
      "Epoch 24/250\n",
      "31/36 [========================>.....] - ETA: 0s - loss: 0.2047 - accuracy: 0.9052\n",
      "Epoch 00024: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2107 - accuracy: 0.9023 - val_loss: 0.4852 - val_accuracy: 0.8351\n",
      "Epoch 25/250\n",
      "28/36 [======================>.......] - ETA: 0s - loss: 0.2304 - accuracy: 0.8996\n",
      "Epoch 00025: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2383 - accuracy: 0.9014 - val_loss: 0.4978 - val_accuracy: 0.8316\n",
      "Epoch 26/250\n",
      "30/36 [========================>.....] - ETA: 0s - loss: 0.2439 - accuracy: 0.9031\n",
      "Epoch 00026: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2502 - accuracy: 0.9032 - val_loss: 0.4776 - val_accuracy: 0.8246\n",
      "Epoch 27/250\n",
      "29/36 [=======================>......] - ETA: 0s - loss: 0.2657 - accuracy: 0.8933\n",
      "Epoch 00027: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2521 - accuracy: 0.8988 - val_loss: 0.4550 - val_accuracy: 0.8456\n",
      "Epoch 28/250\n",
      "27/36 [=====================>........] - ETA: 0s - loss: 0.2030 - accuracy: 0.9062\n",
      "Epoch 00028: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2103 - accuracy: 0.9049 - val_loss: 0.4854 - val_accuracy: 0.8316\n",
      "Epoch 29/250\n",
      "29/36 [=======================>......] - ETA: 0s - loss: 0.2092 - accuracy: 0.9267\n",
      "Epoch 00029: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2149 - accuracy: 0.9243 - val_loss: 0.5026 - val_accuracy: 0.8386\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/250\n",
      "31/36 [========================>.....] - ETA: 0s - loss: 0.2271 - accuracy: 0.8992\n",
      "Epoch 00030: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2219 - accuracy: 0.9049 - val_loss: 0.4737 - val_accuracy: 0.8246\n",
      "Epoch 31/250\n",
      "29/36 [=======================>......] - ETA: 0s - loss: 0.2303 - accuracy: 0.9052\n",
      "Epoch 00031: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2218 - accuracy: 0.9111 - val_loss: 0.5016 - val_accuracy: 0.8316\n",
      "Epoch 32/250\n",
      "30/36 [========================>.....] - ETA: 0s - loss: 0.2437 - accuracy: 0.9052\n",
      "Epoch 00032: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2328 - accuracy: 0.9093 - val_loss: 0.4441 - val_accuracy: 0.8351\n",
      "Epoch 33/250\n",
      "25/36 [===================>..........] - ETA: 0s - loss: 0.2227 - accuracy: 0.8963\n",
      "Epoch 00033: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2254 - accuracy: 0.8926 - val_loss: 0.4716 - val_accuracy: 0.8456\n",
      "Epoch 34/250\n",
      "27/36 [=====================>........] - ETA: 0s - loss: 0.2187 - accuracy: 0.9086\n",
      "Epoch 00034: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2186 - accuracy: 0.9058 - val_loss: 0.4789 - val_accuracy: 0.8281\n",
      "Epoch 35/250\n",
      "27/36 [=====================>........] - ETA: 0s - loss: 0.2135 - accuracy: 0.9201\n",
      "Epoch 00035: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2199 - accuracy: 0.9111 - val_loss: 0.4340 - val_accuracy: 0.8281\n",
      "Epoch 36/250\n",
      "26/36 [====================>.........] - ETA: 0s - loss: 0.2272 - accuracy: 0.8990\n",
      "Epoch 00036: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2300 - accuracy: 0.8952 - val_loss: 0.4327 - val_accuracy: 0.8456\n",
      "Epoch 37/250\n",
      "27/36 [=====================>........] - ETA: 0s - loss: 0.2035 - accuracy: 0.9109\n",
      "Epoch 00037: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2024 - accuracy: 0.9120 - val_loss: 0.4657 - val_accuracy: 0.8281\n",
      "Epoch 38/250\n",
      "27/36 [=====================>........] - ETA: 0s - loss: 0.1998 - accuracy: 0.9155\n",
      "Epoch 00038: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2044 - accuracy: 0.9173 - val_loss: 0.5267 - val_accuracy: 0.8246\n",
      "Epoch 39/250\n",
      "30/36 [========================>.....] - ETA: 0s - loss: 0.1915 - accuracy: 0.9187\n",
      "Epoch 00039: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1955 - accuracy: 0.9181 - val_loss: 0.5298 - val_accuracy: 0.8351\n",
      "Epoch 40/250\n",
      "29/36 [=======================>......] - ETA: 0s - loss: 0.2197 - accuracy: 0.9095\n",
      "Epoch 00040: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2256 - accuracy: 0.9032 - val_loss: 0.5293 - val_accuracy: 0.8211\n",
      "Epoch 41/250\n",
      "28/36 [======================>.......] - ETA: 0s - loss: 0.1814 - accuracy: 0.9163\n",
      "Epoch 00041: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1988 - accuracy: 0.9120 - val_loss: 0.5345 - val_accuracy: 0.8351\n",
      "Epoch 42/250\n",
      "30/36 [========================>.....] - ETA: 0s - loss: 0.2247 - accuracy: 0.9010\n",
      "Epoch 00042: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2296 - accuracy: 0.8996 - val_loss: 0.5238 - val_accuracy: 0.8246\n",
      "Epoch 43/250\n",
      "26/36 [====================>.........] - ETA: 0s - loss: 0.2184 - accuracy: 0.9026\n",
      "Epoch 00043: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2047 - accuracy: 0.9111 - val_loss: 0.4661 - val_accuracy: 0.8351\n",
      "Epoch 44/250\n",
      "27/36 [=====================>........] - ETA: 0s - loss: 0.2126 - accuracy: 0.8993\n",
      "Epoch 00044: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2160 - accuracy: 0.8979 - val_loss: 0.5386 - val_accuracy: 0.8281\n",
      "Epoch 45/250\n",
      "27/36 [=====================>........] - ETA: 0s - loss: 0.2105 - accuracy: 0.9109\n",
      "Epoch 00045: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1991 - accuracy: 0.9137 - val_loss: 0.4984 - val_accuracy: 0.8281\n",
      "Epoch 46/250\n",
      "32/36 [=========================>....] - ETA: 0s - loss: 0.2025 - accuracy: 0.9121\n",
      "Epoch 00046: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.2079 - accuracy: 0.9102 - val_loss: 0.5276 - val_accuracy: 0.8316\n",
      "Epoch 47/250\n",
      "30/36 [========================>.....] - ETA: 0s - loss: 0.2178 - accuracy: 0.9042\n",
      "Epoch 00047: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2110 - accuracy: 0.9067 - val_loss: 0.5495 - val_accuracy: 0.8211\n",
      "Epoch 48/250\n",
      "29/36 [=======================>......] - ETA: 0s - loss: 0.2231 - accuracy: 0.9181\n",
      "Epoch 00048: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2192 - accuracy: 0.9146 - val_loss: 0.4682 - val_accuracy: 0.8491\n",
      "Epoch 49/250\n",
      "30/36 [========================>.....] - ETA: 0s - loss: 0.2071 - accuracy: 0.9104\n",
      "Epoch 00049: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2001 - accuracy: 0.9137 - val_loss: 0.4966 - val_accuracy: 0.8316\n",
      "Epoch 50/250\n",
      "30/36 [========================>.....] - ETA: 0s - loss: 0.2359 - accuracy: 0.9021\n",
      "Epoch 00050: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2260 - accuracy: 0.9058 - val_loss: 0.4740 - val_accuracy: 0.8316\n",
      "Epoch 51/250\n",
      "28/36 [======================>.......] - ETA: 0s - loss: 0.2234 - accuracy: 0.9219\n",
      "Epoch 00051: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2133 - accuracy: 0.9234 - val_loss: 0.5141 - val_accuracy: 0.8386\n",
      "Epoch 52/250\n",
      "29/36 [=======================>......] - ETA: 0s - loss: 0.2114 - accuracy: 0.9159\n",
      "Epoch 00052: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2210 - accuracy: 0.9111 - val_loss: 0.4488 - val_accuracy: 0.8316\n",
      "Epoch 53/250\n",
      "27/36 [=====================>........] - ETA: 0s - loss: 0.1943 - accuracy: 0.9109\n",
      "Epoch 00053: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2007 - accuracy: 0.9085 - val_loss: 0.4921 - val_accuracy: 0.8491\n",
      "Epoch 54/250\n",
      "26/36 [====================>.........] - ETA: 0s - loss: 0.2158 - accuracy: 0.9026\n",
      "Epoch 00054: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2478 - accuracy: 0.9005 - val_loss: 0.4640 - val_accuracy: 0.8456\n",
      "Epoch 55/250\n",
      "29/36 [=======================>......] - ETA: 0s - loss: 0.2148 - accuracy: 0.9062\n",
      "Epoch 00055: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2030 - accuracy: 0.9076 - val_loss: 0.5178 - val_accuracy: 0.8491\n",
      "Epoch 56/250\n",
      "30/36 [========================>.....] - ETA: 0s - loss: 0.2007 - accuracy: 0.9104 ETA: 0s - loss: 0.1883 - accuracy: 0.91\n",
      "Epoch 00056: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1990 - accuracy: 0.9129 - val_loss: 0.5113 - val_accuracy: 0.8421\n",
      "Epoch 57/250\n",
      "19/36 [==============>...............] - ETA: 0s - loss: 0.1733 - accuracy: 0.9243\n",
      "Epoch 00057: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1965 - accuracy: 0.9093 - val_loss: 0.4931 - val_accuracy: 0.8491\n",
      "Epoch 58/250\n",
      "27/36 [=====================>........] - ETA: 0s - loss: 0.1848 - accuracy: 0.9329\n",
      "Epoch 00058: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1901 - accuracy: 0.9278 - val_loss: 0.4940 - val_accuracy: 0.8421\n",
      "Epoch 59/250\n",
      "28/36 [======================>.......] - ETA: 0s - loss: 0.1657 - accuracy: 0.9241\n",
      "Epoch 00059: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1769 - accuracy: 0.9234 - val_loss: 0.5328 - val_accuracy: 0.8421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/250\n",
      "30/36 [========================>.....] - ETA: 0s - loss: 0.1960 - accuracy: 0.9187\n",
      "Epoch 00060: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1973 - accuracy: 0.9164 - val_loss: 0.5126 - val_accuracy: 0.8386\n",
      "Epoch 61/250\n",
      "26/36 [====================>.........] - ETA: 0s - loss: 0.2304 - accuracy: 0.9075\n",
      "Epoch 00061: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2285 - accuracy: 0.9067 - val_loss: 0.5357 - val_accuracy: 0.8316\n",
      "Epoch 62/250\n",
      "31/36 [========================>.....] - ETA: 0s - loss: 0.2165 - accuracy: 0.8931\n",
      "Epoch 00062: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2285 - accuracy: 0.8944 - val_loss: 0.4457 - val_accuracy: 0.8491\n",
      "Epoch 63/250\n",
      "27/36 [=====================>........] - ETA: 0s - loss: 0.2011 - accuracy: 0.9167\n",
      "Epoch 00063: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2086 - accuracy: 0.9137 - val_loss: 0.4509 - val_accuracy: 0.8491\n",
      "Epoch 64/250\n",
      "27/36 [=====================>........] - ETA: 0s - loss: 0.1934 - accuracy: 0.9178\n",
      "Epoch 00064: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2151 - accuracy: 0.9093 - val_loss: 0.4925 - val_accuracy: 0.8386\n",
      "Epoch 65/250\n",
      "28/36 [======================>.......] - ETA: 0s - loss: 0.2083 - accuracy: 0.9074\n",
      "Epoch 00065: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2082 - accuracy: 0.9093 - val_loss: 0.4793 - val_accuracy: 0.8351\n",
      "Epoch 66/250\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.2078 - accuracy: 0.9125\n",
      "Epoch 00066: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.2074 - accuracy: 0.9120 - val_loss: 0.5010 - val_accuracy: 0.8281\n",
      "Epoch 67/250\n",
      "29/36 [=======================>......] - ETA: 0s - loss: 0.1892 - accuracy: 0.9159\n",
      "Epoch 00067: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1931 - accuracy: 0.9155 - val_loss: 0.4972 - val_accuracy: 0.8316\n",
      "Epoch 68/250\n",
      "26/36 [====================>.........] - ETA: 0s - loss: 0.1822 - accuracy: 0.9255\n",
      "Epoch 00068: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1831 - accuracy: 0.9234 - val_loss: 0.4933 - val_accuracy: 0.8211\n",
      "Epoch 69/250\n",
      "25/36 [===================>..........] - ETA: 0s - loss: 0.2109 - accuracy: 0.9162\n",
      "Epoch 00069: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2011 - accuracy: 0.9217 - val_loss: 0.4975 - val_accuracy: 0.8491\n",
      "Epoch 70/250\n",
      "27/36 [=====================>........] - ETA: 0s - loss: 0.2193 - accuracy: 0.9132\n",
      "Epoch 00070: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2034 - accuracy: 0.9208 - val_loss: 0.5084 - val_accuracy: 0.8421\n",
      "Epoch 71/250\n",
      "22/36 [=================>............] - ETA: 0s - loss: 0.2405 - accuracy: 0.9020\n",
      "Epoch 00071: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.2191 - accuracy: 0.9067 - val_loss: 0.5022 - val_accuracy: 0.8421\n",
      "Epoch 72/250\n",
      "30/36 [========================>.....] - ETA: 0s - loss: 0.2369 - accuracy: 0.9156\n",
      "Epoch 00072: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2399 - accuracy: 0.9190 - val_loss: 0.5491 - val_accuracy: 0.8316\n",
      "Epoch 73/250\n",
      "30/36 [========================>.....] - ETA: 0s - loss: 0.2440 - accuracy: 0.9073\n",
      "Epoch 00073: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2508 - accuracy: 0.9067 - val_loss: 0.4627 - val_accuracy: 0.8316\n",
      "Epoch 74/250\n",
      "32/36 [=========================>....] - ETA: 0s - loss: 0.2145 - accuracy: 0.9062\n",
      "Epoch 00074: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2157 - accuracy: 0.9058 - val_loss: 0.5337 - val_accuracy: 0.8281\n",
      "Epoch 75/250\n",
      "28/36 [======================>.......] - ETA: 0s - loss: 0.2022 - accuracy: 0.9252\n",
      "Epoch 00075: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2088 - accuracy: 0.9225 - val_loss: 0.5438 - val_accuracy: 0.8316\n",
      "Epoch 76/250\n",
      "28/36 [======================>.......] - ETA: 0s - loss: 0.2157 - accuracy: 0.9208\n",
      "Epoch 00076: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2050 - accuracy: 0.9217 - val_loss: 0.5896 - val_accuracy: 0.8351\n",
      "Epoch 77/250\n",
      "28/36 [======================>.......] - ETA: 0s - loss: 0.2347 - accuracy: 0.9062\n",
      "Epoch 00077: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2310 - accuracy: 0.9049 - val_loss: 0.5267 - val_accuracy: 0.8105\n",
      "Epoch 78/250\n",
      "29/36 [=======================>......] - ETA: 0s - loss: 0.2117 - accuracy: 0.9116\n",
      "Epoch 00078: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2038 - accuracy: 0.9155 - val_loss: 0.4547 - val_accuracy: 0.8281\n",
      "Epoch 79/250\n",
      "28/36 [======================>.......] - ETA: 0s - loss: 0.2221 - accuracy: 0.9074\n",
      "Epoch 00079: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2217 - accuracy: 0.9058 - val_loss: 0.4458 - val_accuracy: 0.8281\n",
      "Epoch 80/250\n",
      "27/36 [=====================>........] - ETA: 0s - loss: 0.1739 - accuracy: 0.9236\n",
      "Epoch 00080: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1891 - accuracy: 0.9155 - val_loss: 0.5084 - val_accuracy: 0.8316\n",
      "Epoch 81/250\n",
      "30/36 [========================>.....] - ETA: 0s - loss: 0.1849 - accuracy: 0.9187\n",
      "Epoch 00081: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1809 - accuracy: 0.9181 - val_loss: 0.5289 - val_accuracy: 0.8246\n",
      "Epoch 82/250\n",
      "29/36 [=======================>......] - ETA: 0s - loss: 0.1959 - accuracy: 0.9246\n",
      "Epoch 00082: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1970 - accuracy: 0.9217 - val_loss: 0.5482 - val_accuracy: 0.8246\n",
      "Epoch 83/250\n",
      "25/36 [===================>..........] - ETA: 0s - loss: 0.2169 - accuracy: 0.9125\n",
      "Epoch 00083: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2075 - accuracy: 0.9199 - val_loss: 0.4819 - val_accuracy: 0.8211\n",
      "Epoch 84/250\n",
      "26/36 [====================>.........] - ETA: 0s - loss: 0.1752 - accuracy: 0.93 - ETA: 0s - loss: 0.2153 - accuracy: 0.9062\n",
      "Epoch 00084: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2016 - accuracy: 0.9093 - val_loss: 0.5301 - val_accuracy: 0.8386\n",
      "Epoch 85/250\n",
      "28/36 [======================>.......] - ETA: 0s - loss: 0.2017 - accuracy: 0.9096\n",
      "Epoch 00085: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1992 - accuracy: 0.9085 - val_loss: 0.5459 - val_accuracy: 0.8070\n",
      "Epoch 86/250\n",
      "28/36 [======================>.......] - ETA: 0s - loss: 0.1953 - accuracy: 0.9085\n",
      "Epoch 00086: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1859 - accuracy: 0.9137 - val_loss: 0.5393 - val_accuracy: 0.8246\n",
      "Epoch 87/250\n",
      "26/36 [====================>.........] - ETA: 0s - loss: 0.2049 - accuracy: 0.9123\n",
      "Epoch 00087: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2041 - accuracy: 0.9085 - val_loss: 0.5005 - val_accuracy: 0.8386\n",
      "Epoch 88/250\n",
      "30/36 [========================>.....] - ETA: 0s - loss: 0.1927 - accuracy: 0.90 - ETA: 0s - loss: 0.1906 - accuracy: 0.9125\n",
      "Epoch 00088: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1860 - accuracy: 0.9164 - val_loss: 0.5843 - val_accuracy: 0.8281\n",
      "Epoch 89/250\n",
      "28/36 [======================>.......] - ETA: 0s - loss: 0.2005 - accuracy: 0.9085\n",
      "Epoch 00089: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2036 - accuracy: 0.9040 - val_loss: 0.5428 - val_accuracy: 0.8246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/250\n",
      "30/36 [========================>.....] - ETA: 0s - loss: 0.1766 - accuracy: 0.9208\n",
      "Epoch 00090: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1815 - accuracy: 0.9190 - val_loss: 0.5301 - val_accuracy: 0.8316\n",
      "Epoch 91/250\n",
      "26/36 [====================>.........] - ETA: 0s - loss: 0.1898 - accuracy: 0.9291\n",
      "Epoch 00091: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1824 - accuracy: 0.9252 - val_loss: 0.5377 - val_accuracy: 0.8281\n",
      "Epoch 92/250\n",
      "27/36 [=====================>........] - ETA: 0s - loss: 0.2215 - accuracy: 0.9039\n",
      "Epoch 00092: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2071 - accuracy: 0.9093 - val_loss: 0.4830 - val_accuracy: 0.8246\n",
      "Epoch 93/250\n",
      "27/36 [=====================>........] - ETA: 0s - loss: 0.2108 - accuracy: 0.9213\n",
      "Epoch 00093: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2055 - accuracy: 0.9173 - val_loss: 0.5595 - val_accuracy: 0.8246\n",
      "Epoch 94/250\n",
      "30/36 [========================>.....] - ETA: 0s - loss: 0.1847 - accuracy: 0.9104\n",
      "Epoch 00094: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1814 - accuracy: 0.9129 - val_loss: 0.5138 - val_accuracy: 0.8246\n",
      "Epoch 95/250\n",
      "28/36 [======================>.......] - ETA: 0s - loss: 0.1900 - accuracy: 0.9185\n",
      "Epoch 00095: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1802 - accuracy: 0.9217 - val_loss: 0.5523 - val_accuracy: 0.8421\n",
      "Epoch 96/250\n",
      "29/36 [=======================>......] - ETA: 0s - loss: 0.1630 - accuracy: 0.9213\n",
      "Epoch 00096: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1615 - accuracy: 0.9234 - val_loss: 0.6218 - val_accuracy: 0.8281\n",
      "Epoch 97/250\n",
      "28/36 [======================>.......] - ETA: 0s - loss: 0.1747 - accuracy: 0.9353\n",
      "Epoch 00097: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1797 - accuracy: 0.9287 - val_loss: 0.6109 - val_accuracy: 0.8491\n",
      "Epoch 98/250\n",
      "29/36 [=======================>......] - ETA: 0s - loss: 0.1859 - accuracy: 0.9224\n",
      "Epoch 00098: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1850 - accuracy: 0.9234 - val_loss: 0.5711 - val_accuracy: 0.8316\n",
      "Epoch 99/250\n",
      "26/36 [====================>.........] - ETA: 0s - loss: 0.1934 - accuracy: 0.9147\n",
      "Epoch 00099: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1921 - accuracy: 0.9129 - val_loss: 0.5620 - val_accuracy: 0.8281\n",
      "Epoch 100/250\n",
      "30/36 [========================>.....] - ETA: 0s - loss: 0.1865 - accuracy: 0.9281\n",
      "Epoch 00100: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1864 - accuracy: 0.9269 - val_loss: 0.5509 - val_accuracy: 0.8281\n",
      "Epoch 101/250\n",
      "30/36 [========================>.....] - ETA: 0s - loss: 0.1701 - accuracy: 0.9250\n",
      "Epoch 00101: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1754 - accuracy: 0.9252 - val_loss: 0.6197 - val_accuracy: 0.8281\n",
      "Epoch 102/250\n",
      "27/36 [=====================>........] - ETA: 0s - loss: 0.1793 - accuracy: 0.9178\n",
      "Epoch 00102: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1777 - accuracy: 0.9199 - val_loss: 0.6639 - val_accuracy: 0.8351\n",
      "Epoch 103/250\n",
      "26/36 [====================>.........] - ETA: 0s - loss: 0.2123 - accuracy: 0.9219\n",
      "Epoch 00103: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1932 - accuracy: 0.9225 - val_loss: 0.6240 - val_accuracy: 0.8316\n",
      "Epoch 104/250\n",
      "27/36 [=====================>........] - ETA: 0s - loss: 0.1951 - accuracy: 0.9144\n",
      "Epoch 00104: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1907 - accuracy: 0.9164 - val_loss: 0.5458 - val_accuracy: 0.8386\n",
      "Epoch 105/250\n",
      "26/36 [====================>.........] - ETA: 0s - loss: 0.1892 - accuracy: 0.9171\n",
      "Epoch 00105: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1932 - accuracy: 0.9129 - val_loss: 0.5916 - val_accuracy: 0.8246\n",
      "Epoch 106/250\n",
      "29/36 [=======================>......] - ETA: 0s - loss: 0.2095 - accuracy: 0.9073\n",
      "Epoch 00106: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2123 - accuracy: 0.9058 - val_loss: 0.5473 - val_accuracy: 0.8281\n",
      "Epoch 107/250\n",
      "28/36 [======================>.......] - ETA: 0s - loss: 0.1677 - accuracy: 0.9252\n",
      "Epoch 00107: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1860 - accuracy: 0.9164 - val_loss: 0.5554 - val_accuracy: 0.8281\n",
      "Epoch 108/250\n",
      "31/36 [========================>.....] - ETA: 0s - loss: 0.1926 - accuracy: 0.9143\n",
      "Epoch 00108: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1916 - accuracy: 0.9146 - val_loss: 0.4878 - val_accuracy: 0.8316\n",
      "Epoch 109/250\n",
      "25/36 [===================>..........] - ETA: 0s - loss: 0.1839 - accuracy: 0.9100\n",
      "Epoch 00109: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1964 - accuracy: 0.9111 - val_loss: 0.5113 - val_accuracy: 0.8246\n",
      "Epoch 110/250\n",
      "27/36 [=====================>........] - ETA: 0s - loss: 0.1958 - accuracy: 0.9144\n",
      "Epoch 00110: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1951 - accuracy: 0.9129 - val_loss: 0.5541 - val_accuracy: 0.8211\n",
      "Epoch 111/250\n",
      "27/36 [=====================>........] - ETA: 0s - loss: 0.2047 - accuracy: 0.9120\n",
      "Epoch 00111: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2095 - accuracy: 0.9076 - val_loss: 0.5174 - val_accuracy: 0.8105\n",
      "Epoch 112/250\n",
      "28/36 [======================>.......] - ETA: 0s - loss: 0.1885 - accuracy: 0.9118\n",
      "Epoch 00112: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1905 - accuracy: 0.9181 - val_loss: 0.5106 - val_accuracy: 0.8105\n",
      "Epoch 113/250\n",
      "27/36 [=====================>........] - ETA: 0s - loss: 0.1854 - accuracy: 0.9363\n",
      "Epoch 00113: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1824 - accuracy: 0.9349 - val_loss: 0.5662 - val_accuracy: 0.8140\n",
      "Epoch 114/250\n",
      "30/36 [========================>.....] - ETA: 0s - loss: 0.1891 - accuracy: 0.9135\n",
      "Epoch 00114: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1918 - accuracy: 0.9129 - val_loss: 0.5995 - val_accuracy: 0.8386\n",
      "Epoch 115/250\n",
      "29/36 [=======================>......] - ETA: 0s - loss: 0.1989 - accuracy: 0.9159\n",
      "Epoch 00115: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2017 - accuracy: 0.9146 - val_loss: 0.5910 - val_accuracy: 0.8316\n",
      "Epoch 116/250\n",
      "30/36 [========================>.....] - ETA: 0s - loss: 0.1927 - accuracy: 0.9292\n",
      "Epoch 00116: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1889 - accuracy: 0.9313 - val_loss: 0.5406 - val_accuracy: 0.8386\n",
      "Epoch 117/250\n",
      "30/36 [========================>.....] - ETA: 0s - loss: 0.1824 - accuracy: 0.9208\n",
      "Epoch 00117: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1759 - accuracy: 0.9234 - val_loss: 0.5633 - val_accuracy: 0.8281\n",
      "Epoch 118/250\n",
      "26/36 [====================>.........] - ETA: 0s - loss: 0.1848 - accuracy: 0.9243\n",
      "Epoch 00118: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1868 - accuracy: 0.9269 - val_loss: 0.5987 - val_accuracy: 0.8140\n",
      "Epoch 119/250\n",
      "26/36 [====================>.........] - ETA: 0s - loss: 0.1596 - accuracy: 0.9363\n",
      "Epoch 00119: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1712 - accuracy: 0.9261 - val_loss: 0.5939 - val_accuracy: 0.8386\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/250\n",
      "31/36 [========================>.....] - ETA: 0s - loss: 0.1623 - accuracy: 0.9274\n",
      "Epoch 00120: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1686 - accuracy: 0.9261 - val_loss: 0.5697 - val_accuracy: 0.8035\n",
      "Epoch 121/250\n",
      "30/36 [========================>.....] - ETA: 0s - loss: 0.1940 - accuracy: 0.9250 ETA: 0s - loss: 0.2307 - accuracy: 0.90\n",
      "Epoch 00121: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1981 - accuracy: 0.9243 - val_loss: 0.6332 - val_accuracy: 0.8211\n",
      "Epoch 122/250\n",
      "28/36 [======================>.......] - ETA: 0s - loss: 0.1757 - accuracy: 0.9308\n",
      "Epoch 00122: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1869 - accuracy: 0.9234 - val_loss: 0.6212 - val_accuracy: 0.8035\n",
      "Epoch 123/250\n",
      "28/36 [======================>.......] - ETA: 0s - loss: 0.1678 - accuracy: 0.9252\n",
      "Epoch 00123: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1571 - accuracy: 0.9349 - val_loss: 0.6353 - val_accuracy: 0.8351\n",
      "Epoch 124/250\n",
      "29/36 [=======================>......] - ETA: 0s - loss: 0.1964 - accuracy: 0.9084\n",
      "Epoch 00124: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1907 - accuracy: 0.9102 - val_loss: 0.6365 - val_accuracy: 0.8316\n",
      "Epoch 125/250\n",
      "27/36 [=====================>........] - ETA: 0s - loss: 0.1919 - accuracy: 0.9109\n",
      "Epoch 00125: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1837 - accuracy: 0.9155 - val_loss: 0.5826 - val_accuracy: 0.8281\n",
      "Epoch 126/250\n",
      "28/36 [======================>.......] - ETA: 0s - loss: 0.2143 - accuracy: 0.9141\n",
      "Epoch 00126: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2115 - accuracy: 0.9111 - val_loss: 0.6132 - val_accuracy: 0.8246\n",
      "Epoch 127/250\n",
      "26/36 [====================>.........] - ETA: 0s - loss: 0.1712 - accuracy: 0.9171\n",
      "Epoch 00127: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1835 - accuracy: 0.9173 - val_loss: 0.6263 - val_accuracy: 0.8281\n",
      "Epoch 128/250\n",
      "30/36 [========================>.....] - ETA: 0s - loss: 0.1873 - accuracy: 0.9240\n",
      "Epoch 00128: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1871 - accuracy: 0.9243 - val_loss: 0.5736 - val_accuracy: 0.8491\n",
      "Epoch 129/250\n",
      "27/36 [=====================>........] - ETA: 0s - loss: 0.1859 - accuracy: 0.9225\n",
      "Epoch 00129: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1922 - accuracy: 0.9155 - val_loss: 0.6461 - val_accuracy: 0.8175\n",
      "Epoch 130/250\n",
      "30/36 [========================>.....] - ETA: 0s - loss: 0.1718 - accuracy: 0.92 - ETA: 0s - loss: 0.1749 - accuracy: 0.9146\n",
      "Epoch 00130: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1935 - accuracy: 0.9137 - val_loss: 0.6739 - val_accuracy: 0.8246\n",
      "Epoch 131/250\n",
      "28/36 [======================>.......] - ETA: 0s - loss: 0.1968 - accuracy: 0.9085\n",
      "Epoch 00131: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2002 - accuracy: 0.9111 - val_loss: 0.5858 - val_accuracy: 0.8281\n",
      "Epoch 132/250\n",
      "28/36 [======================>.......] - ETA: 0s - loss: 0.2063 - accuracy: 0.9297\n",
      "Epoch 00132: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2082 - accuracy: 0.9261 - val_loss: 0.6490 - val_accuracy: 0.8316\n",
      "Epoch 133/250\n",
      "28/36 [======================>.......] - ETA: 0s - loss: 0.1922 - accuracy: 0.9241\n",
      "Epoch 00133: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1905 - accuracy: 0.9243 - val_loss: 0.6834 - val_accuracy: 0.8281\n",
      "Epoch 134/250\n",
      "29/36 [=======================>......] - ETA: 0s - loss: 0.2184 - accuracy: 0.9246\n",
      "Epoch 00134: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2192 - accuracy: 0.9225 - val_loss: 0.6359 - val_accuracy: 0.8316\n",
      "Epoch 135/250\n",
      "28/36 [======================>.......] - ETA: 0s - loss: 0.1812 - accuracy: 0.9286\n",
      "Epoch 00135: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1727 - accuracy: 0.9313 - val_loss: 0.6359 - val_accuracy: 0.8351\n",
      "Epoch 136/250\n",
      "27/36 [=====================>........] - ETA: 0s - loss: 0.2066 - accuracy: 0.9167\n",
      "Epoch 00136: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1998 - accuracy: 0.9164 - val_loss: 0.6487 - val_accuracy: 0.8281\n",
      "Epoch 137/250\n",
      "28/36 [======================>.......] - ETA: 0s - loss: 0.1814 - accuracy: 0.9330\n",
      "Epoch 00137: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1834 - accuracy: 0.9305 - val_loss: 0.6531 - val_accuracy: 0.8281\n",
      "Epoch 138/250\n",
      "29/36 [=======================>......] - ETA: 0s - loss: 0.1418 - accuracy: 0.9397\n",
      "Epoch 00138: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1562 - accuracy: 0.9340 - val_loss: 0.7122 - val_accuracy: 0.8246\n",
      "Epoch 139/250\n",
      "27/36 [=====================>........] - ETA: 0s - loss: 0.1760 - accuracy: 0.9225\n",
      "Epoch 00139: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1827 - accuracy: 0.9199 - val_loss: 0.6313 - val_accuracy: 0.8351\n",
      "Epoch 140/250\n",
      "22/36 [=================>............] - ETA: 0s - loss: 0.1775 - accuracy: 0.9247\n",
      "Epoch 00140: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1862 - accuracy: 0.9181 - val_loss: 0.6398 - val_accuracy: 0.8211\n",
      "Epoch 141/250\n",
      "30/36 [========================>.....] - ETA: 0s - loss: 0.1892 - accuracy: 0.9167\n",
      "Epoch 00141: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1849 - accuracy: 0.9164 - val_loss: 0.5803 - val_accuracy: 0.8246\n",
      "Epoch 142/250\n",
      "31/36 [========================>.....] - ETA: 0s - loss: 0.1809 - accuracy: 0.9234\n",
      "Epoch 00142: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1746 - accuracy: 0.9243 - val_loss: 0.6157 - val_accuracy: 0.8211\n",
      "Epoch 143/250\n",
      "28/36 [======================>.......] - ETA: 0s - loss: 0.1977 - accuracy: 0.9152\n",
      "Epoch 00143: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1836 - accuracy: 0.9199 - val_loss: 0.6322 - val_accuracy: 0.8211\n",
      "Epoch 144/250\n",
      "28/36 [======================>.......] - ETA: 0s - loss: 0.2239 - accuracy: 0.9286\n",
      "Epoch 00144: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2095 - accuracy: 0.9278 - val_loss: 0.6201 - val_accuracy: 0.8140\n",
      "Epoch 145/250\n",
      "29/36 [=======================>......] - ETA: 0s - loss: 0.1831 - accuracy: 0.9289\n",
      "Epoch 00145: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1898 - accuracy: 0.9243 - val_loss: 0.5745 - val_accuracy: 0.8211\n",
      "Epoch 146/250\n",
      "30/36 [========================>.....] - ETA: 0s - loss: 0.2037 - accuracy: 0.9292\n",
      "Epoch 00146: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1925 - accuracy: 0.9322 - val_loss: 0.5838 - val_accuracy: 0.8035\n",
      "Epoch 147/250\n",
      "29/36 [=======================>......] - ETA: 0s - loss: 0.1761 - accuracy: 0.9332\n",
      "Epoch 00147: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1763 - accuracy: 0.9340 - val_loss: 0.6085 - val_accuracy: 0.8281\n",
      "Epoch 148/250\n",
      "26/36 [====================>.........] - ETA: 0s - loss: 0.1849 - accuracy: 0.9315\n",
      "Epoch 00148: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1725 - accuracy: 0.9357 - val_loss: 0.6065 - val_accuracy: 0.8351\n",
      "Epoch 149/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/36 [========================>.....] - ETA: 0s - loss: 0.2127 - accuracy: 0.9260\n",
      "Epoch 00149: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2019 - accuracy: 0.9287 - val_loss: 0.6650 - val_accuracy: 0.8070\n",
      "Epoch 150/250\n",
      "29/36 [=======================>......] - ETA: 0s - loss: 0.1768 - accuracy: 0.9246\n",
      "Epoch 00150: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1782 - accuracy: 0.9252 - val_loss: 0.6383 - val_accuracy: 0.8281\n",
      "Epoch 151/250\n",
      "26/36 [====================>.........] - ETA: 0s - loss: 0.2695 - accuracy: 0.9171\n",
      "Epoch 00151: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2622 - accuracy: 0.9111 - val_loss: 0.5538 - val_accuracy: 0.8140\n",
      "Epoch 152/250\n",
      "28/36 [======================>.......] - ETA: 0s - loss: 0.1785 - accuracy: 0.9286\n",
      "Epoch 00152: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1779 - accuracy: 0.9278 - val_loss: 0.5592 - val_accuracy: 0.8421\n",
      "Epoch 153/250\n",
      "27/36 [=====================>........] - ETA: 0s - loss: 0.1593 - accuracy: 0.9317\n",
      "Epoch 00153: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1843 - accuracy: 0.9269 - val_loss: 0.5991 - val_accuracy: 0.8175\n",
      "Epoch 154/250\n",
      "32/36 [=========================>....] - ETA: 0s - loss: 0.1651 - accuracy: 0.9297\n",
      "Epoch 00154: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1586 - accuracy: 0.9322 - val_loss: 0.6426 - val_accuracy: 0.8351\n",
      "Epoch 155/250\n",
      "32/36 [=========================>....] - ETA: 0s - loss: 0.1884 - accuracy: 0.9160\n",
      "Epoch 00155: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1875 - accuracy: 0.9173 - val_loss: 0.5929 - val_accuracy: 0.8316\n",
      "Epoch 156/250\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.1650 - accuracy: 0.9277\n",
      "Epoch 00156: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1635 - accuracy: 0.9287 - val_loss: 0.5796 - val_accuracy: 0.8316\n",
      "Epoch 157/250\n",
      "16/36 [============>.................] - ETA: 0s - loss: 0.1980 - accuracy: 0.9219\n",
      "Epoch 00157: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1783 - accuracy: 0.9278 - val_loss: 0.6208 - val_accuracy: 0.8246\n",
      "Epoch 158/250\n",
      "33/36 [==========================>...] - ETA: 0s - loss: 0.1733 - accuracy: 0.9375\n",
      "Epoch 00158: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1735 - accuracy: 0.9357 - val_loss: 0.5637 - val_accuracy: 0.8351\n",
      "Epoch 159/250\n",
      "30/36 [========================>.....] - ETA: 0s - loss: 0.2006 - accuracy: 0.9240\n",
      "Epoch 00159: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1949 - accuracy: 0.9261 - val_loss: 0.5543 - val_accuracy: 0.8211\n",
      "Epoch 160/250\n",
      "22/36 [=================>............] - ETA: 0s - loss: 0.1922 - accuracy: 0.9134\n",
      "Epoch 00160: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1861 - accuracy: 0.9164 - val_loss: 0.5849 - val_accuracy: 0.8386\n",
      "Epoch 161/250\n",
      "27/36 [=====================>........] - ETA: 0s - loss: 0.1558 - accuracy: 0.9375\n",
      "Epoch 00161: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1583 - accuracy: 0.9401 - val_loss: 0.5822 - val_accuracy: 0.8421\n",
      "Epoch 162/250\n",
      "29/36 [=======================>......] - ETA: 0s - loss: 0.1589 - accuracy: 0.9267\n",
      "Epoch 00162: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1697 - accuracy: 0.9208 - val_loss: 0.6640 - val_accuracy: 0.8246\n",
      "Epoch 163/250\n",
      "29/36 [=======================>......] - ETA: 0s - loss: 0.1686 - accuracy: 0.9300\n",
      "Epoch 00163: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1694 - accuracy: 0.9278 - val_loss: 0.6514 - val_accuracy: 0.8175\n",
      "Epoch 164/250\n",
      "26/36 [====================>.........] - ETA: 0s - loss: 0.1907 - accuracy: 0.9219\n",
      "Epoch 00164: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1893 - accuracy: 0.9199 - val_loss: 0.5857 - val_accuracy: 0.8105\n",
      "Epoch 165/250\n",
      "28/36 [======================>.......] - ETA: 0s - loss: 0.1853 - accuracy: 0.9196\n",
      "Epoch 00165: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1762 - accuracy: 0.9208 - val_loss: 0.6254 - val_accuracy: 0.8281\n",
      "Epoch 166/250\n",
      "30/36 [========================>.....] - ETA: 0s - loss: 0.2151 - accuracy: 0.91 - ETA: 0s - loss: 0.1878 - accuracy: 0.9219\n",
      "Epoch 00166: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1980 - accuracy: 0.9234 - val_loss: 0.5753 - val_accuracy: 0.8175\n",
      "Epoch 167/250\n",
      "28/36 [======================>.......] - ETA: 0s - loss: 0.1732 - accuracy: 0.9286\n",
      "Epoch 00167: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1755 - accuracy: 0.9243 - val_loss: 0.6541 - val_accuracy: 0.8175\n",
      "Epoch 168/250\n",
      "27/36 [=====================>........] - ETA: 0s - loss: 0.1745 - accuracy: 0.9317\n",
      "Epoch 00168: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1905 - accuracy: 0.9269 - val_loss: 0.6145 - val_accuracy: 0.8211\n",
      "Epoch 169/250\n",
      "27/36 [=====================>........] - ETA: 0s - loss: 0.1693 - accuracy: 0.9294\n",
      "Epoch 00169: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1762 - accuracy: 0.9287 - val_loss: 0.5922 - val_accuracy: 0.8246\n",
      "Epoch 170/250\n",
      "27/36 [=====================>........] - ETA: 0s - loss: 0.1771 - accuracy: 0.9225\n",
      "Epoch 00170: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1752 - accuracy: 0.9181 - val_loss: 0.6449 - val_accuracy: 0.8175\n",
      "Epoch 171/250\n",
      "25/36 [===================>..........] - ETA: 0s - loss: 0.1926 - accuracy: 0.9237\n",
      "Epoch 00171: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1743 - accuracy: 0.9278 - val_loss: 0.5939 - val_accuracy: 0.8281\n",
      "Epoch 172/250\n",
      "27/36 [=====================>........] - ETA: 0s - loss: 0.1742 - accuracy: 0.9225\n",
      "Epoch 00172: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1669 - accuracy: 0.9287 - val_loss: 0.6227 - val_accuracy: 0.8105\n",
      "Epoch 173/250\n",
      "29/36 [=======================>......] - ETA: 0s - loss: 0.1791 - accuracy: 0.9256\n",
      "Epoch 00173: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1867 - accuracy: 0.9217 - val_loss: 0.6499 - val_accuracy: 0.8386\n",
      "Epoch 174/250\n",
      "27/36 [=====================>........] - ETA: 0s - loss: 0.1723 - accuracy: 0.9271\n",
      "Epoch 00174: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1756 - accuracy: 0.9287 - val_loss: 0.6333 - val_accuracy: 0.8351\n",
      "Epoch 175/250\n",
      "28/36 [======================>.......] - ETA: 0s - loss: 0.1754 - accuracy: 0.9163\n",
      "Epoch 00175: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1768 - accuracy: 0.9199 - val_loss: 0.6537 - val_accuracy: 0.8246\n",
      "Epoch 176/250\n",
      "30/36 [========================>.....] - ETA: 0s - loss: 0.1539 - accuracy: 0.9333\n",
      "Epoch 00176: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1624 - accuracy: 0.9322 - val_loss: 0.6776 - val_accuracy: 0.8211\n",
      "Epoch 177/250\n",
      "28/36 [======================>.......] - ETA: 0s - loss: 0.2013 - accuracy: 0.9219\n",
      "Epoch 00177: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2147 - accuracy: 0.9208 - val_loss: 0.6669 - val_accuracy: 0.8211\n",
      "Epoch 178/250\n",
      "25/36 [===================>..........] - ETA: 0s - loss: 0.1813 - accuracy: 0.9300\n",
      "Epoch 00178: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1805 - accuracy: 0.9261 - val_loss: 0.6242 - val_accuracy: 0.8281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 179/250\n",
      "27/36 [=====================>........] - ETA: 0s - loss: 0.1652 - accuracy: 0.9271\n",
      "Epoch 00179: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1679 - accuracy: 0.9287 - val_loss: 0.6151 - val_accuracy: 0.8386\n",
      "Epoch 180/250\n",
      "26/36 [====================>.........] - ETA: 0s - loss: 0.2066 - accuracy: 0.9195\n",
      "Epoch 00180: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1894 - accuracy: 0.9234 - val_loss: 0.5769 - val_accuracy: 0.8421\n",
      "Epoch 181/250\n",
      "23/36 [==================>...........] - ETA: 0s - loss: 0.1763 - accuracy: 0.9212\n",
      "Epoch 00181: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1740 - accuracy: 0.9243 - val_loss: 0.6205 - val_accuracy: 0.8281\n",
      "Epoch 182/250\n",
      "30/36 [========================>.....] - ETA: 0s - loss: 0.1806 - accuracy: 0.9271\n",
      "Epoch 00182: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1886 - accuracy: 0.9225 - val_loss: 0.6341 - val_accuracy: 0.8351\n",
      "Epoch 183/250\n",
      "28/36 [======================>.......] - ETA: 0s - loss: 0.1928 - accuracy: 0.9196\n",
      "Epoch 00183: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1772 - accuracy: 0.9243 - val_loss: 0.5874 - val_accuracy: 0.8281\n",
      "Epoch 184/250\n",
      "29/36 [=======================>......] - ETA: 0s - loss: 0.1692 - accuracy: 0.9332\n",
      "Epoch 00184: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1777 - accuracy: 0.9252 - val_loss: 0.6228 - val_accuracy: 0.8351\n",
      "Epoch 185/250\n",
      "26/36 [====================>.........] - ETA: 0s - loss: 0.1863 - accuracy: 0.9243\n",
      "Epoch 00185: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1794 - accuracy: 0.9287 - val_loss: 0.6384 - val_accuracy: 0.8281\n",
      "Epoch 186/250\n",
      "30/36 [========================>.....] - ETA: 0s - loss: 0.2067 - accuracy: 0.9208\n",
      "Epoch 00186: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2058 - accuracy: 0.9190 - val_loss: 0.6642 - val_accuracy: 0.8246\n",
      "Epoch 187/250\n",
      "27/36 [=====================>........] - ETA: 0s - loss: 0.1871 - accuracy: 0.9306\n",
      "Epoch 00187: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1861 - accuracy: 0.9243 - val_loss: 0.6397 - val_accuracy: 0.8246\n",
      "Epoch 188/250\n",
      "28/36 [======================>.......] - ETA: 0s - loss: 0.1542 - accuracy: 0.9286\n",
      "Epoch 00188: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1691 - accuracy: 0.9261 - val_loss: 0.6982 - val_accuracy: 0.8211\n",
      "Epoch 189/250\n",
      "29/36 [=======================>......] - ETA: 0s - loss: 0.1691 - accuracy: 0.9310\n",
      "Epoch 00189: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1686 - accuracy: 0.9313 - val_loss: 0.6657 - val_accuracy: 0.8316\n",
      "Epoch 190/250\n",
      "31/36 [========================>.....] - ETA: 0s - loss: 0.2027 - accuracy: 0.9254\n",
      "Epoch 00190: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2011 - accuracy: 0.9269 - val_loss: 0.6487 - val_accuracy: 0.8281\n",
      "Epoch 191/250\n",
      "27/36 [=====================>........] - ETA: 0s - loss: 0.1602 - accuracy: 0.9317\n",
      "Epoch 00191: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1775 - accuracy: 0.9225 - val_loss: 0.6667 - val_accuracy: 0.8246\n",
      "Epoch 192/250\n",
      "28/36 [======================>.......] - ETA: 0s - loss: 0.1677 - accuracy: 0.9230\n",
      "Epoch 00192: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1681 - accuracy: 0.9234 - val_loss: 0.6456 - val_accuracy: 0.8211\n",
      "Epoch 193/250\n",
      "28/36 [======================>.......] - ETA: 0s - loss: 0.2039 - accuracy: 0.9219\n",
      "Epoch 00193: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2059 - accuracy: 0.9199 - val_loss: 0.6526 - val_accuracy: 0.8246\n",
      "Epoch 194/250\n",
      "27/36 [=====================>........] - ETA: 0s - loss: 0.1532 - accuracy: 0.9329\n",
      "Epoch 00194: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1521 - accuracy: 0.9340 - val_loss: 0.6481 - val_accuracy: 0.8175\n",
      "Epoch 195/250\n",
      "30/36 [========================>.....] - ETA: 0s - loss: 0.1795 - accuracy: 0.9135\n",
      "Epoch 00195: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1699 - accuracy: 0.9173 - val_loss: 0.6736 - val_accuracy: 0.8246\n",
      "Epoch 196/250\n",
      "29/36 [=======================>......] - ETA: 0s - loss: 0.1903 - accuracy: 0.9159\n",
      "Epoch 00196: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1938 - accuracy: 0.9137 - val_loss: 0.6001 - val_accuracy: 0.8211\n",
      "Epoch 197/250\n",
      "29/36 [=======================>......] - ETA: 0s - loss: 0.1821 - accuracy: 0.9203\n",
      "Epoch 00197: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1743 - accuracy: 0.9252 - val_loss: 0.6430 - val_accuracy: 0.8316\n",
      "Epoch 198/250\n",
      "26/36 [====================>.........] - ETA: 0s - loss: 0.1701 - accuracy: 0.9207\n",
      "Epoch 00198: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1641 - accuracy: 0.9287 - val_loss: 0.6372 - val_accuracy: 0.8316\n",
      "Epoch 199/250\n",
      "28/36 [======================>.......] - ETA: 0s - loss: 0.1534 - accuracy: 0.9397\n",
      "Epoch 00199: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1694 - accuracy: 0.9322 - val_loss: 0.6841 - val_accuracy: 0.8351\n",
      "Epoch 200/250\n",
      "30/36 [========================>.....] - ETA: 0s - loss: 0.2289 - accuracy: 0.9344\n",
      "Epoch 00200: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2492 - accuracy: 0.9261 - val_loss: 0.6323 - val_accuracy: 0.8386\n",
      "Epoch 201/250\n",
      "28/36 [======================>.......] - ETA: 0s - loss: 0.1783 - accuracy: 0.9185\n",
      "Epoch 00201: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1788 - accuracy: 0.9155 - val_loss: 0.6145 - val_accuracy: 0.8351\n",
      "Epoch 202/250\n",
      "28/36 [======================>.......] - ETA: 0s - loss: 0.1671 - accuracy: 0.9230\n",
      "Epoch 00202: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1653 - accuracy: 0.9243 - val_loss: 0.6640 - val_accuracy: 0.8246\n",
      "Epoch 203/250\n",
      "29/36 [=======================>......] - ETA: 0s - loss: 0.1935 - accuracy: 0.9246\n",
      "Epoch 00203: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1859 - accuracy: 0.9234 - val_loss: 0.6405 - val_accuracy: 0.8211\n",
      "Epoch 204/250\n",
      "27/36 [=====================>........] - ETA: 0s - loss: 0.1612 - accuracy: 0.9259\n",
      "Epoch 00204: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1709 - accuracy: 0.9199 - val_loss: 0.5599 - val_accuracy: 0.8351\n",
      "Epoch 205/250\n",
      "26/36 [====================>.........] - ETA: 0s - loss: 0.1517 - accuracy: 0.9363\n",
      "Epoch 00205: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1472 - accuracy: 0.9393 - val_loss: 0.6479 - val_accuracy: 0.8316\n",
      "Epoch 206/250\n",
      "26/36 [====================>.........] - ETA: 0s - loss: 0.1692 - accuracy: 0.9243\n",
      "Epoch 00206: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1615 - accuracy: 0.9278 - val_loss: 0.6292 - val_accuracy: 0.8211\n",
      "Epoch 207/250\n",
      "28/36 [======================>.......] - ETA: 0s - loss: 0.1648 - accuracy: 0.9342\n",
      "Epoch 00207: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1590 - accuracy: 0.9375 - val_loss: 0.6729 - val_accuracy: 0.8246\n",
      "Epoch 208/250\n",
      "27/36 [=====================>........] - ETA: 0s - loss: 0.1870 - accuracy: 0.9271\n",
      "Epoch 00208: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1789 - accuracy: 0.9305 - val_loss: 0.6360 - val_accuracy: 0.8211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 209/250\n",
      "29/36 [=======================>......] - ETA: 0s - loss: 0.1699 - accuracy: 0.9256\n",
      "Epoch 00209: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1673 - accuracy: 0.9278 - val_loss: 0.6487 - val_accuracy: 0.8211\n",
      "Epoch 210/250\n",
      "28/36 [======================>.......] - ETA: 0s - loss: 0.1775 - accuracy: 0.9342\n",
      "Epoch 00210: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1736 - accuracy: 0.9349 - val_loss: 0.6300 - val_accuracy: 0.8211\n",
      "Epoch 211/250\n",
      "29/36 [=======================>......] - ETA: 0s - loss: 0.1808 - accuracy: 0.9224\n",
      "Epoch 00211: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1820 - accuracy: 0.9225 - val_loss: 0.6643 - val_accuracy: 0.8316\n",
      "Epoch 212/250\n",
      "26/36 [====================>.........] - ETA: 0s - loss: 0.1671 - accuracy: 0.9279\n",
      "Epoch 00212: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1724 - accuracy: 0.9261 - val_loss: 0.5962 - val_accuracy: 0.8351\n",
      "Epoch 213/250\n",
      "28/36 [======================>.......] - ETA: 0s - loss: 0.1718 - accuracy: 0.9196\n",
      "Epoch 00213: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1718 - accuracy: 0.9190 - val_loss: 0.5229 - val_accuracy: 0.8316\n",
      "Epoch 214/250\n",
      "28/36 [======================>.......] - ETA: 0s - loss: 0.1679 - accuracy: 0.9330\n",
      "Epoch 00214: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1822 - accuracy: 0.9340 - val_loss: 0.6352 - val_accuracy: 0.8386\n",
      "Epoch 215/250\n",
      "28/36 [======================>.......] - ETA: 0s - loss: 0.1936 - accuracy: 0.9319\n",
      "Epoch 00215: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1894 - accuracy: 0.9287 - val_loss: 0.5894 - val_accuracy: 0.8316\n",
      "Epoch 216/250\n",
      "29/36 [=======================>......] - ETA: 0s - loss: 0.1883 - accuracy: 0.9267\n",
      "Epoch 00216: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1778 - accuracy: 0.9305 - val_loss: 0.5554 - val_accuracy: 0.8246\n",
      "Epoch 217/250\n",
      "25/36 [===================>..........] - ETA: 0s - loss: 0.1968 - accuracy: 0.9275\n",
      "Epoch 00217: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1989 - accuracy: 0.9199 - val_loss: 0.5512 - val_accuracy: 0.8281\n",
      "Epoch 218/250\n",
      "26/36 [====================>.........] - ETA: 0s - loss: 0.1718 - accuracy: 0.9303\n",
      "Epoch 00218: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1911 - accuracy: 0.9252 - val_loss: 0.5164 - val_accuracy: 0.8281\n",
      "Epoch 219/250\n",
      "28/36 [======================>.......] - ETA: 0s - loss: 0.1778 - accuracy: 0.9297\n",
      "Epoch 00219: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1818 - accuracy: 0.9269 - val_loss: 0.6465 - val_accuracy: 0.8351\n",
      "Epoch 220/250\n",
      "29/36 [=======================>......] - ETA: 0s - loss: 0.1895 - accuracy: 0.9278\n",
      "Epoch 00220: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1796 - accuracy: 0.9305 - val_loss: 0.6686 - val_accuracy: 0.8351\n",
      "Epoch 221/250\n",
      "27/36 [=====================>........] - ETA: 0s - loss: 0.1892 - accuracy: 0.9074\n",
      "Epoch 00221: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1936 - accuracy: 0.9067 - val_loss: 0.6272 - val_accuracy: 0.8386\n",
      "Epoch 222/250\n",
      "21/36 [================>.............] - ETA: 0s - loss: 0.2133 - accuracy: 0.9211\n",
      "Epoch 00222: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.2025 - accuracy: 0.9199 - val_loss: 0.5691 - val_accuracy: 0.8526\n",
      "Epoch 223/250\n",
      "30/36 [========================>.....] - ETA: 0s - loss: 0.1831 - accuracy: 0.9292\n",
      "Epoch 00223: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1767 - accuracy: 0.9313 - val_loss: 0.6256 - val_accuracy: 0.8281\n",
      "Epoch 224/250\n",
      "32/36 [=========================>....] - ETA: 0s - loss: 0.1763 - accuracy: 0.9336\n",
      "Epoch 00224: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1754 - accuracy: 0.9331 - val_loss: 0.5354 - val_accuracy: 0.8421\n",
      "Epoch 225/250\n",
      "29/36 [=======================>......] - ETA: 0s - loss: 0.1853 - accuracy: 0.9095\n",
      "Epoch 00225: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1957 - accuracy: 0.9058 - val_loss: 0.5693 - val_accuracy: 0.8281\n",
      "Epoch 226/250\n",
      "29/36 [=======================>......] - ETA: 0s - loss: 0.1733 - accuracy: 0.9332\n",
      "Epoch 00226: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1746 - accuracy: 0.9313 - val_loss: 0.5920 - val_accuracy: 0.8281\n",
      "Epoch 227/250\n",
      "27/36 [=====================>........] - ETA: 0s - loss: 0.1635 - accuracy: 0.9352\n",
      "Epoch 00227: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1552 - accuracy: 0.9357 - val_loss: 0.6554 - val_accuracy: 0.8316\n",
      "Epoch 228/250\n",
      "27/36 [=====================>........] - ETA: 0s - loss: 0.1832 - accuracy: 0.9201\n",
      "Epoch 00228: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1933 - accuracy: 0.9190 - val_loss: 0.6065 - val_accuracy: 0.8281\n",
      "Epoch 229/250\n",
      "26/36 [====================>.........] - ETA: 0s - loss: 0.1555 - accuracy: 0.9219\n",
      "Epoch 00229: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1619 - accuracy: 0.9278 - val_loss: 0.5756 - val_accuracy: 0.8316\n",
      "Epoch 230/250\n",
      "30/36 [========================>.....] - ETA: 0s - loss: 0.1511 - accuracy: 0.9333\n",
      "Epoch 00230: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1553 - accuracy: 0.9305 - val_loss: 0.5644 - val_accuracy: 0.8456\n",
      "Epoch 231/250\n",
      "27/36 [=====================>........] - ETA: 0s - loss: 0.1708 - accuracy: 0.9259\n",
      "Epoch 00231: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1530 - accuracy: 0.9331 - val_loss: 0.6288 - val_accuracy: 0.8316\n",
      "Epoch 232/250\n",
      "32/36 [=========================>....] - ETA: 0s - loss: 0.1416 - accuracy: 0.9375\n",
      "Epoch 00232: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1421 - accuracy: 0.9375 - val_loss: 0.7067 - val_accuracy: 0.8456\n",
      "Epoch 233/250\n",
      "28/36 [======================>.......] - ETA: 0s - loss: 0.1768 - accuracy: 0.9275\n",
      "Epoch 00233: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1722 - accuracy: 0.9305 - val_loss: 0.5976 - val_accuracy: 0.8386\n",
      "Epoch 234/250\n",
      "26/36 [====================>.........] - ETA: 0s - loss: 0.1313 - accuracy: 0.9423\n",
      "Epoch 00234: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1507 - accuracy: 0.9340 - val_loss: 0.6321 - val_accuracy: 0.8281\n",
      "Epoch 235/250\n",
      "26/36 [====================>.........] - ETA: 0s - loss: 0.1671 - accuracy: 0.9195\n",
      "Epoch 00235: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1654 - accuracy: 0.9225 - val_loss: 0.5771 - val_accuracy: 0.8351\n",
      "Epoch 236/250\n",
      "28/36 [======================>.......] - ETA: 0s - loss: 0.1733 - accuracy: 0.9297\n",
      "Epoch 00236: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1704 - accuracy: 0.9331 - val_loss: 0.6066 - val_accuracy: 0.8281\n",
      "Epoch 237/250\n",
      "28/36 [======================>.......] - ETA: 0s - loss: 0.1581 - accuracy: 0.9431\n",
      "Epoch 00237: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1651 - accuracy: 0.9384 - val_loss: 0.5826 - val_accuracy: 0.8386\n",
      "Epoch 238/250\n",
      "27/36 [=====================>........] - ETA: 0s - loss: 0.1701 - accuracy: 0.9340\n",
      "Epoch 00238: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1834 - accuracy: 0.9357 - val_loss: 0.5925 - val_accuracy: 0.8281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 239/250\n",
      "26/36 [====================>.........] - ETA: 0s - loss: 0.1589 - accuracy: 0.9351\n",
      "Epoch 00239: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1618 - accuracy: 0.9313 - val_loss: 0.6215 - val_accuracy: 0.8316\n",
      "Epoch 240/250\n",
      "29/36 [=======================>......] - ETA: 0s - loss: 0.1622 - accuracy: 0.9321\n",
      "Epoch 00240: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1618 - accuracy: 0.9322 - val_loss: 0.6979 - val_accuracy: 0.8281\n",
      "Epoch 241/250\n",
      "28/36 [======================>.......] - ETA: 0s - loss: 0.1737 - accuracy: 0.9152\n",
      "Epoch 00241: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1650 - accuracy: 0.9190 - val_loss: 0.5875 - val_accuracy: 0.8491\n",
      "Epoch 242/250\n",
      "32/36 [=========================>....] - ETA: 0s - loss: 0.1565 - accuracy: 0.9395\n",
      "Epoch 00242: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1567 - accuracy: 0.9375 - val_loss: 0.5901 - val_accuracy: 0.8281\n",
      "Epoch 243/250\n",
      "29/36 [=======================>......] - ETA: 0s - loss: 0.1661 - accuracy: 0.9310\n",
      "Epoch 00243: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1744 - accuracy: 0.9296 - val_loss: 0.5798 - val_accuracy: 0.8281\n",
      "Epoch 244/250\n",
      "28/36 [======================>.......] - ETA: 0s - loss: 0.1599 - accuracy: 0.9386\n",
      "Epoch 00244: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1662 - accuracy: 0.9349 - val_loss: 0.6049 - val_accuracy: 0.8351\n",
      "Epoch 245/250\n",
      "31/36 [========================>.....] - ETA: 0s - loss: 0.1830 - accuracy: 0.9234\n",
      "Epoch 00245: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1821 - accuracy: 0.9243 - val_loss: 0.6080 - val_accuracy: 0.8281\n",
      "Epoch 246/250\n",
      "30/36 [========================>.....] - ETA: 0s - loss: 0.1712 - accuracy: 0.9229\n",
      "Epoch 00246: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1656 - accuracy: 0.9261 - val_loss: 0.6145 - val_accuracy: 0.8316\n",
      "Epoch 247/250\n",
      "27/36 [=====================>........] - ETA: 0s - loss: 0.1581 - accuracy: 0.9271\n",
      "Epoch 00247: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1724 - accuracy: 0.9322 - val_loss: 0.6951 - val_accuracy: 0.8316\n",
      "Epoch 248/250\n",
      "30/36 [========================>.....] - ETA: 0s - loss: 0.1624 - accuracy: 0.9396\n",
      "Epoch 00248: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1669 - accuracy: 0.9349 - val_loss: 0.6418 - val_accuracy: 0.8281\n",
      "Epoch 249/250\n",
      "26/36 [====================>.........] - ETA: 0s - loss: 0.1320 - accuracy: 0.9447\n",
      "Epoch 00249: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1575 - accuracy: 0.9331 - val_loss: 0.6216 - val_accuracy: 0.8211\n",
      "Epoch 250/250\n",
      "27/36 [=====================>........] - ETA: 0s - loss: 0.1587 - accuracy: 0.9271\n",
      "Epoch 00250: val_loss did not improve from 0.43222\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1502 - accuracy: 0.9340 - val_loss: 0.6165 - val_accuracy: 0.8316\n",
      "Training completed in time:  0:00:45.629367\n"
     ]
    }
   ],
   "source": [
    "## Trianing my model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from datetime import datetime \n",
    "\n",
    "num_epochs = 250\n",
    "num_batch_size = 32\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/audio_classification.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "start = datetime.now()\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(X_test, y_test), callbacks=[checkpointer], verbose=1)\n",
    "\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(\"Training completed in time: \", duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af782b0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8280701637268066\n"
     ]
    }
   ],
   "source": [
    "test_accuracy=model.evaluate(X_test,y_test,verbose=0)\n",
    "print(test_accuracy[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a3c3d971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.3063849e+02,  1.1165551e+02, -8.7104301e+01,  5.8447609e+01,\n",
       "       -4.3384937e+01,  2.9110548e+01, -1.6375883e+01,  2.3683420e+01,\n",
       "       -4.0308213e+00, -7.6600137e+00,  1.0622702e+01, -1.4019006e+01,\n",
       "        1.2874228e+01, -4.9438267e+00,  8.0033770e+00, -5.4981914e+00,\n",
       "        9.6272564e+00, -5.0295973e-01, -2.7353075e+00,  6.3974915e+00,\n",
       "       -3.7514639e+00,  3.1424506e+00, -6.9262648e+00,  6.9378138e-02,\n",
       "       -5.4487967e+00,  1.1041200e+00, -2.0198722e+00, -2.2589972e+00,\n",
       "       -4.1758195e-01, -3.9879074e+00, -8.0276453e-01, -1.3649640e+00,\n",
       "        5.1823225e+00, -1.9565439e+00, -1.1405403e-01, -1.8208673e+00,\n",
       "       -3.9585388e-01, -5.8239591e-01, -1.7330813e+00, -1.6288793e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "658a63bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\hpmsi\\AppData\\Local\\Temp\\ipykernel_31516\\1990934593.py:1: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([5, 6, 5, 5, 6, 1, 5, 1, 1, 0, 4, 3, 0, 2, 6, 5, 2, 1, 3, 5, 5, 1,\n",
       "       5, 3, 5, 0, 3, 2, 4, 5, 0, 4, 0, 1, 4, 3, 0, 0, 2, 4, 0, 6, 5, 4,\n",
       "       5, 1, 3, 4, 4, 6, 1, 2, 5, 0, 6, 2, 0, 6, 2, 0, 2, 4, 1, 2, 6, 6,\n",
       "       6, 1, 0, 4, 6, 6, 6, 5, 4, 6, 0, 3, 0, 6, 5, 3, 4, 4, 0, 3, 2, 6,\n",
       "       5, 3, 2, 3, 1, 3, 1, 6, 6, 6, 1, 3, 2, 5, 4, 3, 6, 5, 5, 3, 1, 4,\n",
       "       0, 0, 2, 2, 2, 3, 5, 3, 0, 6, 2, 4, 4, 6, 3, 1, 4, 6, 3, 1, 6, 6,\n",
       "       4, 2, 0, 6, 1, 4, 0, 3, 3, 0, 2, 0, 5, 4, 0, 5, 5, 6, 6, 1, 5, 0,\n",
       "       4, 5, 3, 2, 5, 5, 2, 2, 6, 6, 0, 0, 0, 5, 4, 1, 5, 6, 1, 4, 5, 6,\n",
       "       0, 0, 3, 2, 2, 0, 6, 5, 1, 2, 0, 2, 6, 4, 6, 5, 3, 6, 0, 5, 4, 1,\n",
       "       4, 0, 6, 5, 0, 6, 4, 6, 6, 6, 5, 6, 5, 5, 0, 0, 1, 4, 1, 6, 2, 5,\n",
       "       5, 1, 6, 5, 5, 1, 4, 3, 0, 6, 3, 6, 2, 4, 0, 3, 2, 3, 2, 6, 0, 3,\n",
       "       3, 4, 6, 4, 0, 5, 6, 4, 3, 3, 2, 3, 2, 0, 5, 1, 6, 0, 6, 0, 2, 2,\n",
       "       2, 1, 5, 5, 3, 1, 3, 5, 0, 5, 6, 5, 1, 1, 2, 6, 6, 4, 6, 6, 3],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5eb5f2a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.6470540e+02  2.6732979e+01 -6.8700127e+01 -5.0641990e+00\n",
      "  -4.7408385e+00  3.3975830e+01 -2.8795290e+00 -3.2337460e-01\n",
      "  -2.3452206e+01  2.3330618e+01  1.1420064e+01 -9.9012012e+00\n",
      "  -1.6797682e+01  1.7326614e+01 -6.9102807e+00 -9.5692414e-01\n",
      "   3.5794382e+00  2.0893061e+00 -5.4386148e+00  2.2695320e+01\n",
      "  -1.0479029e+01 -3.1278226e+00  2.3204505e+00  1.7750673e-02\n",
      "   5.3236084e+00  7.7043641e-01 -3.4205668e+00  3.8611009e+00\n",
      "  -2.0670660e+00  9.6238403e+00 -1.1486684e+01 -4.0032697e-01\n",
      "   3.8467505e+00  1.9821206e+00  1.7422614e+00  1.9203607e+00\n",
      "  -5.8944219e-01 -4.3522793e-01  9.7204828e+00 -5.9988484e+00]]\n",
      "[6]\n",
      "['screaming']\n"
     ]
    }
   ],
   "source": [
    "filename=r\"C:\\Users\\hpmsi\\Downloads\\132106__sironboy__woman-scream (1).wav\"\n",
    "audio, sample_rate = librosa.load(filename, res_type='kaiser_fast') \n",
    "mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "mfccs_scaled_features = np.mean(mfccs_features.T,axis=0)\n",
    "\n",
    "#print(mfccs_scaled_features)\n",
    "mfccs_scaled_features=mfccs_scaled_features.reshape(1,-1)\n",
    "print(mfccs_scaled_features)\n",
    "#print(mfccs_scaled_features.shape)\n",
    "predicted_label=model.predict_classes(mfccs_scaled_features)\n",
    "print(predicted_label)\n",
    "prediction_class = labelencoder.inverse_transform(predicted_label) \n",
    "print(prediction_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f7400c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
